{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt','r').read().splitlines()\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "torch.set_default_device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chars = ['.'] + sorted(list(set(''.join(words))))\n",
    "chars_bi = []\n",
    "for i in chars:\n",
    "    for j in chars:\n",
    "        ch_ = i+j\n",
    "        chars_bi.append(''.join(ch_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi_bi = {s:i for i,s in enumerate(chars_bi)}\n",
    "itos_bi = {i:s for s,i in stoi_bi.items()}\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  196113\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi_bi[ch1+ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix3)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ',num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# g = torch.Generator().manual_seed(2147483647)\n",
    "xenc = F.one_hot(xs, num_classes=729).float()\n",
    "W = torch.randn((729, 27), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.28286075592041\n",
      "2.282288074493408\n",
      "2.2817182540893555\n",
      "2.281151294708252\n",
      "2.2805874347686768\n",
      "2.28002667427063\n",
      "2.2794690132141113\n",
      "2.278914213180542\n",
      "2.278362274169922\n",
      "2.277813196182251\n",
      "2.2772672176361084\n",
      "2.276723861694336\n",
      "2.2761833667755127\n",
      "2.2756457328796387\n",
      "2.275110960006714\n",
      "2.274578809738159\n",
      "2.2740492820739746\n",
      "2.2735228538513184\n",
      "2.272998809814453\n",
      "2.272477626800537\n",
      "2.271959066390991\n",
      "2.2714428901672363\n",
      "2.2709295749664307\n",
      "2.270418882369995\n",
      "2.2699105739593506\n",
      "2.269404888153076\n",
      "2.268901824951172\n",
      "2.2684013843536377\n",
      "2.2679030895233154\n",
      "2.2674076557159424\n",
      "2.266914129257202\n",
      "2.2664237022399902\n",
      "2.265935182571411\n",
      "2.265449285507202\n",
      "2.2649660110473633\n",
      "2.2644846439361572\n",
      "2.2640058994293213\n",
      "2.2635293006896973\n",
      "2.2630550861358643\n",
      "2.2625832557678223\n",
      "2.2621138095855713\n",
      "2.261646270751953\n",
      "2.261181116104126\n",
      "2.26071834564209\n",
      "2.2602579593658447\n",
      "2.2597992420196533\n",
      "2.259342908859253\n",
      "2.2588887214660645\n",
      "2.258436918258667\n",
      "2.2579872608184814\n",
      "2.2575392723083496\n",
      "2.257093667984009\n",
      "2.256649971008301\n",
      "2.256208896636963\n",
      "2.2557692527770996\n",
      "2.2553322315216064\n",
      "2.254896879196167\n",
      "2.2544634342193604\n",
      "2.2540323734283447\n",
      "2.253602981567383\n",
      "2.253175735473633\n",
      "2.2527503967285156\n",
      "2.252326726913452\n",
      "2.2519054412841797\n",
      "2.251485824584961\n",
      "2.251068115234375\n",
      "2.250652313232422\n",
      "2.2502384185791016\n",
      "2.249826431274414\n",
      "2.2494163513183594\n",
      "2.2490081787109375\n",
      "2.2486016750335693\n",
      "2.248196840286255\n",
      "2.2477941513061523\n",
      "2.2473931312561035\n",
      "2.2469940185546875\n",
      "2.246596336364746\n",
      "2.2462005615234375\n",
      "2.2458064556121826\n",
      "2.2454142570495605\n",
      "2.2450239658355713\n",
      "2.2446351051330566\n",
      "2.244248151779175\n",
      "2.2438628673553467\n",
      "2.243479013442993\n",
      "2.2430968284606934\n",
      "2.2427165508270264\n",
      "2.242337703704834\n",
      "2.2419607639312744\n",
      "2.2415852546691895\n",
      "2.241211175918579\n",
      "2.2408392429351807\n",
      "2.2404685020446777\n",
      "2.2400994300842285\n",
      "2.239731788635254\n",
      "2.239366054534912\n",
      "2.239001512527466\n",
      "2.2386388778686523\n",
      "2.2382771968841553\n",
      "2.23791766166687\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    W.data += -30 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heleisanaanadupalanizevariaiwidaquravadanazanerevinazonyavisaxhelehazelaneshelichizayoauselesaevalolianafacazelelaradaramenaumevihantelafqugotaleishalyocostayziparanadepokaaamaisubrxzilimanoladayfanabempelesijubronaiharabaiwilodabaramaarhanamaezhazoridadiquwemoshaliyimyefamanoluwbeevaledvryoooluvimasaruxxmelu.\n",
      "habelarisbewaitisarisugasomiaadetamailenazataimevqu.\n",
      "luamelanisazaanadroriamaxmiowzalaaremy.\n",
      "oshalidiwaliasevimimiisnadaristhaysuvadzaladalalyezywzoelanoledeyadelavadoxamasmabrheadayaivemarocevikalchabemosadow.\n",
      "heliregrebeyyeprileberpamalaiharevemesavvemiayjevimerhelilavidaalanemadonaxrheatarvadeoprevihanalidemelemalevicowrevirivaluoremcaunivevauvelmisatocaledivitanoualemademarelomezarotyanbhazyahivwamalyabooproezamelaviloluxalyeveluxnanedryalhaadgiyochadlizarynyomzoreayemaryhaliurevivarsalelelxnakaraalanyasadaiyaiquosaydqxaamidelolymeloluvyemamahalelelalazamadadayolshamehahalevanoxmazuvxruonarasemadevarphoashanavaowainabejamelorohalamadamanvanadazanoruvapavalisuas.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=729).float()\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix % 27 == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
