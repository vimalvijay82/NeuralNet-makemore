{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,2]]\n",
    "xs = torch.tensor(a)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['.'] + sorted(list(set(''.join(words))))\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  196113\n"
     ]
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        # print(ch1, ch2)\n",
    "        xs.append([ix1, ix2])\n",
    "        ys.append(ix3)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.size(0)\n",
    "print('number of examples: ',num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5],\n",
       "        [ 5, 13],\n",
       "        [13, 13],\n",
       "        ...,\n",
       "        [26, 25],\n",
       "        [25, 26],\n",
       "        [26, 24]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 13,  1,  ..., 26, 24,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196113, 54])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc = xenc.view(-1,2*27)\n",
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((2*27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2679367065429688\n",
      "2.267749309539795\n",
      "2.2675657272338867\n",
      "2.2673847675323486\n",
      "2.267207384109497\n",
      "2.267033100128174\n",
      "2.2668616771698\n",
      "2.266692876815796\n",
      "2.2665271759033203\n",
      "2.266364574432373\n",
      "2.2662041187286377\n",
      "2.2660470008850098\n",
      "2.265892267227173\n",
      "2.265739917755127\n",
      "2.265590190887451\n",
      "2.2654428482055664\n",
      "2.265298366546631\n",
      "2.26515531539917\n",
      "2.265015125274658\n",
      "2.2648768424987793\n",
      "2.2647411823272705\n",
      "2.2646074295043945\n",
      "2.2644758224487305\n",
      "2.26434588432312\n",
      "2.264218330383301\n",
      "2.2640926837921143\n",
      "2.2639691829681396\n",
      "2.2638471126556396\n",
      "2.2637274265289307\n",
      "2.2636091709136963\n",
      "2.2634925842285156\n",
      "2.2633779048919678\n",
      "2.2632651329040527\n",
      "2.2631540298461914\n",
      "2.2630441188812256\n",
      "2.2629363536834717\n",
      "2.262829542160034\n",
      "2.2627246379852295\n",
      "2.2626211643218994\n",
      "2.262519121170044\n",
      "2.2624189853668213\n",
      "2.262319564819336\n",
      "2.2622218132019043\n",
      "2.262125253677368\n",
      "2.2620303630828857\n",
      "2.261936664581299\n",
      "2.2618443965911865\n",
      "2.2617530822753906\n",
      "2.2616629600524902\n",
      "2.2615745067596436\n",
      "2.2614872455596924\n",
      "2.2614006996154785\n",
      "2.2613155841827393\n",
      "2.2612314224243164\n",
      "2.261148691177368\n",
      "2.2610666751861572\n",
      "2.260985851287842\n",
      "2.260906219482422\n",
      "2.2608275413513184\n",
      "2.2607500553131104\n",
      "2.2606732845306396\n",
      "2.2605977058410645\n",
      "2.2605230808258057\n",
      "2.260449171066284\n",
      "2.2603766918182373\n",
      "2.2603044509887695\n",
      "2.2602336406707764\n",
      "2.2601635456085205\n",
      "2.260094165802002\n",
      "2.260025978088379\n",
      "2.259958505630493\n",
      "2.2598917484283447\n",
      "2.2598257064819336\n",
      "2.2597603797912598\n",
      "2.2596962451934814\n",
      "2.2596328258514404\n",
      "2.2595701217651367\n",
      "2.2595081329345703\n",
      "2.259446620941162\n",
      "2.2593863010406494\n",
      "2.259326457977295\n",
      "2.2592673301696777\n",
      "2.2592086791992188\n",
      "2.259150981903076\n",
      "2.25909423828125\n",
      "2.259037733078003\n",
      "2.258981704711914\n",
      "2.2589266300201416\n",
      "2.2588722705841064\n",
      "2.2588183879852295\n",
      "2.25876522064209\n",
      "2.2587125301361084\n",
      "2.2586605548858643\n",
      "2.258608818054199\n",
      "2.2585580348968506\n",
      "2.25850772857666\n",
      "2.258457899093628\n",
      "2.258409023284912\n",
      "2.2583601474761963\n",
      "2.2583119869232178\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "    print(loss.item())\n",
    "    \n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counide.\n",
      "cianasad.\n",
      "ca.\n",
      "colay.\n",
      "ca.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix1 = 0\n",
    "    ix2 = random.randint(1,26)\n",
    "    out.append(itos[ix2])\n",
    "\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27).float()\n",
    "        logits = xenc.view(-1,2*27) @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        ix1 = ix2\n",
    "        ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix2])\n",
    "        if ix2 == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
